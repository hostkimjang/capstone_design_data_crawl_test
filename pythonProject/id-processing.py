import sqlite3
import json
import os
import re
import time
import csv
import requests
from difflib import SequenceMatcher


def normalize(text: str) -> str:
    if not text:
        return ''
    text = re.sub(r'\(.*?\)', '', text)
    text = re.sub(r'\s+', '', text)
    text = re.sub(r'[^ã„±-ã…£ê°€-í£\w]', '', text)
    return text.lower()


def extract_address_prefix(address: str, parts: int = 3) -> str:
    if not address:
        return ''
    tokens = address.split()
    return ' '.join(tokens[:parts]) if len(tokens) >= parts else address


def load_all_json_data(web_dir):
    json_files = sorted([
        os.path.join(web_dir, f) for f in os.listdir(web_dir) if f.endswith('.json')
    ])
    all_data = []
    for path in json_files:
        with open(path, 'r', encoding='utf-8') as f:
            all_data.extend(json.load(f))
    return all_data, json_files


def build_db_index_map():
    print("ğŸ” DB ë ˆì½”ë“œ ì¸ë±ì‹± ì¤‘...")
    conn = sqlite3.connect('food_data.db')
    cursor = conn.cursor()

    cursor.execute("""
        SELECT ë²ˆí˜¸, ì‚¬ì—…ì¥ëª…, ë„ë¡œëª…ì „ì²´ì£¼ì†Œ FROM restaurants
    """)
    mapping = {}
    for row in cursor.fetchall():
        name_key = normalize(row[1])
        road_key = normalize(extract_address_prefix(row[2]))
        mapping[(name_key, road_key)] = row[0]  # ë²ˆí˜¸

    conn.close()
    print(f"âœ… DB ì¸ë±ì‹± ì™„ë£Œ: {len(mapping)}ê±´")
    return mapping


def enrich_json_with_ids(all_data, id_map):
    unmatched = []
    enriched = []

    for item in all_data:
        title = item.get("title", "").strip()
        query = item.get("query", "").strip()
        road_address = query[len(title):].strip() if query.startswith(title) else query
        road_prefix = extract_address_prefix(road_address)

        norm_key = (normalize(title), normalize(road_prefix))
        matched_id = id_map.get(norm_key)

        if matched_id:
            print(f"âœ… ë§¤ì¹­ ì„±ê³µ: {title} â†’ {matched_id}")
            item["ë²ˆí˜¸"] = matched_id
            enriched.append(item)
        else:
            print(f"âŒ ë§¤ì¹­ ì‹¤íŒ¨: {title} â†’ {road_prefix}")
            unmatched.append({"title": title, "query": query})

    return enriched, unmatched


def save_enriched_json(enriched, out_path='web_data_enriched.json'):
    with open(out_path, 'w', encoding='utf-8') as f:
        json.dump(enriched, f, ensure_ascii=False, indent=2)
    print(f"ğŸ“¦ ë§¤ì¹­ëœ {len(enriched)}ê±´ ì €ì¥ ì™„ë£Œ â†’ {out_path}")


def save_unmatched(unmatched, out_path='unmatched_log.csv'):
    with open(out_path, 'w', newline='', encoding='utf-8') as f:
        writer = csv.DictWriter(f, fieldnames=['title', 'query'])
        writer.writeheader()
        writer.writerows(unmatched)
    print(f"âš ï¸ ë§¤ì¹­ ì‹¤íŒ¨ {len(unmatched)}ê±´ â†’ {out_path}")


def insert_enriched_data(json_path='web_data_enriched.json', db_path='food_merged_final.db'):
    with open(json_path, 'r', encoding='utf-8') as f:
        enriched = json.load(f)

    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    cursor.execute("""
    CREATE TABLE IF NOT EXISTS restaurant_merged (
        ì‚¬ì—…ì¥ëª… TEXT,
        ì¸í—ˆê°€ì¼ì TEXT,
        ì˜ì—…ìƒíƒœëª… TEXT,
        ìƒì„¸ì˜ì—…ìƒíƒœëª… TEXT,
        ì†Œì¬ì§€ì „ì²´ì£¼ì†Œ TEXT,
        ë„ë¡œëª…ì „ì²´ì£¼ì†Œ TEXT,
        ë„ë¡œëª…ìš°í¸ë²ˆí˜¸ REAL,
        ìµœì¢…ìˆ˜ì •ì‹œì  TEXT,
        ë°ì´í„°ê°±ì‹ ì¼ì TEXT,
        ì—…íƒœêµ¬ë¶„ëª… TEXT,
        ë„¤ì´ë²„_ìƒí˜¸ëª… TEXT,
        ë„¤ì´ë²„_ì£¼ì†Œ TEXT,
        ë„¤ì´ë²„_ì „í™”ë²ˆí˜¸ TEXT,
        ë„¤ì´ë²„_URL TEXT,
        ë„¤ì´ë²„_PLACE_ID_URL TEXT,
        ë„¤ì´ë²„_place_info TEXT,
        ë„¤ì´ë²„_tab_list TEXT
    )
    """)

    source_conn = sqlite3.connect('food_data.db')
    source_cursor = source_conn.cursor()

    inserted = 0
    for idx, item in enumerate(enriched, 1):
        no = item.get("ë²ˆí˜¸")
        if no is None:
            continue

        source_cursor.execute("""
        SELECT ì‚¬ì—…ì¥ëª…, ì¸í—ˆê°€ì¼ì, ì˜ì—…ìƒíƒœëª…, ìƒì„¸ì˜ì—…ìƒíƒœëª…,
               ì†Œì¬ì§€ì „ì²´ì£¼ì†Œ, ë„ë¡œëª…ì „ì²´ì£¼ì†Œ, ë„ë¡œëª…ìš°í¸ë²ˆí˜¸,
               ìµœì¢…ìˆ˜ì •ì‹œì , ë°ì´í„°ê°±ì‹ ì¼ì, ì—…íƒœêµ¬ë¶„ëª…
        FROM restaurants
        WHERE ë²ˆí˜¸ = ?
        """, (no,))

        row = source_cursor.fetchone()
        if not row:
            continue

        place = item.get("place_info", {})
        merged = row + (
            place.get("title", ""),
            place.get("ì£¼ì†Œ", ""),
            place.get("ì „í™”ë²ˆí˜¸", ""),
            item.get("url", ""),
            item.get("unique_links", [""])[0],
            json.dumps(place, ensure_ascii=False),
            json.dumps(item.get("tab_list", []), ensure_ascii=False)
        )

        cursor.execute("""
        INSERT INTO restaurant_merged VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, merged)

        inserted += 1
        if inserted % 100 == 0:
            print(f"ğŸ’¾ ì‚½ì… ì§„í–‰ ì¤‘: {inserted}ê±´")

    conn.commit()
    conn.close()
    source_conn.close()
    print(f"âœ… ìµœì¢… ì‚½ì… ì™„ë£Œ: {inserted}ê±´")


if __name__ == "__main__":
    start = time.time()

    print("ğŸ“¥ JSON ë°ì´í„° ë¡œë“œ ì¤‘...")
    all_data, _ = load_all_json_data("./tmp/web_data")

    print("ğŸ§  ì¸ë±ìŠ¤ ê¸°ë°˜ ë§¤ì¹­ ì¤€ë¹„...")
    id_map = build_db_index_map()
    enriched, unmatched = enrich_json_with_ids(all_data, id_map)

    save_enriched_json(enriched)
    save_unmatched(unmatched)

    # print("ğŸ“Š DB ì‚½ì… ì‹œì‘...")
    # insert_enriched_data()

    end = time.time()
    print(f"â° ì „ì²´ ì†Œìš” ì‹œê°„: {end - start:.2f}ì´ˆ")
