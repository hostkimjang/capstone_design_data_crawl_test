import requests
import time
import json
from datetime import datetime
import sqlite3
import re
from tqdm import tqdm
import os


GRAPHQL_URL = "https://api.place.naver.com/graphql"
HEADERS = {
    "Content-Type": "application/json",
    "User-Agent": "Mozilla/5.0 AppleWebKit/537.36 (KHTML, like Gecko; compatible; Googlebot/2.1; +http://www.google.com/bot.html)",
}

MAX_RETRIES = 5
RETRY_BACKOFF = 2  # seconds
MAX_PAGES = 10

DB_PATH = "./food_merged_final.db"
TABLE_NAME = "restaurant_merged"
BUSINESS_ID_COLUMN = "ë„¤ì´ë²„_PLACE_ID_URL"

def log_failure(business_id, payload, status=None, error=None):
    with open("failed_requests.log", "a", encoding="utf-8") as f:
        f.write(f"[{datetime.now()}] âŒ {business_id} ìš”ì²­ ì‹¤íŒ¨\n")
        f.write(f"Status: {status}\n" if status else "")
        f.write(f"Error: {error}\n" if error else "")
        f.write(f"Payload: {json.dumps(payload, ensure_ascii=False)}\n\n")

def make_payload(business_id, cursors):
    return {
        "operationName": "getPhotoViewerItems",
        "variables": {
            "input": {
                "businessId": business_id,
                "businessType": "restaurant",
                "cursors": cursors,
                "excludeAuthorIds": [],
                "excludeSection": [],
                "excludeClipIds": [],
                "dateRange": ""
            }
        },
        "query": """
        query getPhotoViewerItems($input: PhotoViewerInput) {
          photoViewer(input: $input) {
            cursors {
              id
              startIndex
              hasNext
              lastCursor
              __typename
            }
            photos {
              originalUrl
              width
              height
              desc
              author {
                nickname
              }
              video {
                videoId
                videoUrl
                trailerUrl
              }
              __typename
            }
            __typename
          }
        }
        """
    }

def safe_post_with_retry(business_id, payload):
    for attempt in range(1, MAX_RETRIES + 1):
        try:
            response = requests.post(GRAPHQL_URL, json=payload, headers=HEADERS, timeout=10)
            if response.status_code == 200:
                return response.json()
            elif response.status_code in [429, 500, 502, 503, 504]:
                wait = RETRY_BACKOFF * attempt
                print(f"â³ ì„œë²„ ì˜¤ë¥˜({response.status_code}) - {wait}s í›„ ì¬ì‹œë„ ({attempt}/{MAX_RETRIES})")
                time.sleep(wait)
            else:
                print(f"âŒ ìš”ì²­ ì‹¤íŒ¨ - ìƒíƒœì½”ë“œ: {response.status_code}")
                log_failure(business_id, payload, status=response.status_code)
                break
        except requests.RequestException as e:
            wait = RETRY_BACKOFF * attempt
            print(f"âš ï¸ ì˜ˆì™¸ ë°œìƒ: {e} - {wait}s í›„ ì¬ì‹œë„ ({attempt}/{MAX_RETRIES})")
            time.sleep(wait)
    log_failure(business_id, payload, error="ìµœëŒ€ ì¬ì‹œë„ ì´ˆê³¼")
    return None
def crawl_photos(business_id, max_pages=5):
    all_photos = []
    cursors = [
        {"id": "biz"},
        {"id": "cp0"},
        {"id": "visitorReview"},
        {"id": "clip"},
        {"id": "imgSas"}
    ]

    for page in range(max_pages):
        print(f"ğŸ“„ [{business_id}] í˜ì´ì§€ {page+1} ìš”ì²­ ì¤‘...")
        payload = make_payload(business_id, cursors)
        data = safe_post_with_retry(business_id, payload)

        if not data:
            break

        viewer = data.get('data', {}).get('photoViewer', {})
        photos = viewer.get('photos') or []
        cursors_data = viewer.get('cursors', [])

        if not photos:
            print(f"\nâš ï¸ [{business_id}] ì‚¬ì§„ ì—†ìŒ, ìŠ¤í‚µ")
            break

        for photo in photos:
            if not photo:
                continue
            author = photo.get("author") or {}
            all_photos.append({
                "url": photo.get("originalUrl"),
                "desc": photo.get("desc"),
                "author": author.get("nickname"),
                "video": photo.get("video")
            })

        # ë‹¤ìŒ ì»¤ì„œ í™•ì¸
        next_cursor = None
        for cursor in cursors_data:
            if cursor["id"] == "biz" and cursor.get("hasNext") and cursor.get("lastCursor"):
                next_cursor = cursor["lastCursor"]
        if not next_cursor:
            print(f"\nâœ… [{business_id}] ë‹¤ìŒ ì»¤ì„œ ì—†ìŒ, ì¢…ë£Œ")
            break

        cursors[0] = {"id": "biz", "lastCursor": next_cursor}
        time.sleep(1)

    return all_photos

def save_jsonl(business_id, photos):
    os.makedirs("crawl_photo", exist_ok=True)  # ë””ë ‰í† ë¦¬ ì—†ìœ¼ë©´ ìƒì„±
    filename = os.path.join("crawl_photo", f"photo_{business_id}.jsonl")
    with open(filename, "w", encoding="utf-8") as f:
        for p in photos:
            f.write(json.dumps(p, ensure_ascii=False) + "\n")

def load_business_ids(limit=10):
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    cursor.execute(f"""
        SELECT DISTINCT {BUSINESS_ID_COLUMN}
        FROM {TABLE_NAME}
        WHERE {BUSINESS_ID_COLUMN} IS NOT NULL
        LIMIT ?
    """, (limit,))
    rows = cursor.fetchall()
    conn.close()

    # ì •ê·œì‹ìœ¼ë¡œ ìˆ«ìë§Œ ì¶”ì¶œ
    ids = []
    for row in rows:
        match = re.search(r'/restaurant/(\d+)', row[0])
        if match:
            ids.append(match.group(1))
    return ids


def main():
    business_ids = load_business_ids(limit=100)

    total = len(business_ids)
    success_count = 0
    skip_count = 0
    error_count = 0

    for bid in tqdm(business_ids, desc="ğŸ“¦ ì „ì²´ ì—…ì²´ ì²˜ë¦¬"):
        print(f"\nğŸš€ í¬ë¡¤ë§ ì‹œì‘: {bid}")
        try:
            photos = crawl_photos(bid, max_pages=MAX_PAGES)
            if photos:
                save_jsonl(bid, photos)
                print(f"âœ… ì €ì¥ ì™„ë£Œ: photo_{bid}.jsonl ({len(photos)}ì¥)")
                success_count += 1
            else:
                print(f"âš ï¸ ì‚¬ì§„ ì—†ìŒ ë˜ëŠ” ì‹¤íŒ¨: {bid}")
                skip_count += 1
        except Exception as e:
            print(f"âŒ ì˜ˆì™¸ë¡œ ê±´ë„ˆëœ€: {bid} â†’ {e}")
            error_count += 1
            continue

    # ğŸ“Š ê²°ê³¼ ìš”ì•½ ì¶œë ¥
    print("\nğŸ“Š í¬ë¡¤ë§ ìš”ì•½")
    print(f"ğŸ”¢ ì „ì²´ ì—…ì²´ ìˆ˜: {total}")
    print(f"âœ… ì„±ê³µ (ì‚¬ì§„ ì¡´ì¬): {success_count}")
    print(f"âš ï¸ ì—†ìŒ (ì‚¬ì§„ ì—†ìŒ): {skip_count}")
    print(f"âŒ ì‹¤íŒ¨ (ì—ëŸ¬ ê±´ë„ˆëœ€): {error_count}")


if __name__ == "__main__":
    main()

