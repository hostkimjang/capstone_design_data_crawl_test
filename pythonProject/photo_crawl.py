import asyncio
import json
import os
import random
import re
import sqlite3
import time
import requests
from datetime import datetime
from tqdm import tqdm
from playwright.async_api import async_playwright

DB_PATH = "./food_merged_final.db"
TABLE_NAME = "restaurant_merged"
BUSINESS_ID_COLUMN = "ë„¤ì´ë²„_PLACE_ID_URL"
MAX_PAGES = 10
MAX_RETRIES = 3
MIN_DELAY = 1
MAX_DELAY = 3

# GraphQL ì¿¼ë¦¬ ë°ì´í„°
PHOTO_QUERY = """
query getPhotoViewerItems($input: PhotoViewerInput) {
  photoViewer(input: $input) {
    cursors {
      id
      startIndex
      hasNext
      lastCursor
      __typename
    }
    photos {
      viewId
      originalUrl
      originalDate
      width
      height
      title
      text
      desc
      link
      date
      photoType
      mediaType
      option {
        channelName
        dateString
        playCount
        likeCount
        __typename
      }
      to
      relation
      logId
      author {
        id
        nickname
        from
        imageUrl
        objectId
        url
        borderImageUrl
        __typename
      }
      votedKeywords {
        code
        iconUrl
        iconCode
        name
        __typename
      }
      visitCount
      originType
      isFollowing
      businessName
      rating
      externalLink {
        title
        url
        __typename
      }
      sourceTitle
      moment {
        channelId
        contentId
        momentId
        gdid
        blogRelation
        statAllowYn
        category
        docNo
        __typename
      }
      video {
        videoId
        videoUrl
        trailerUrl
        __typename
      }
      music {
        artists
        title
        __typename
      }
      clip {
        serviceType
        createdAt
        __typename
      }
      __typename
    }
    __typename
  }
}
"""

def log_failure(business_id, payload, error=None):
    with open("failed_requests.log", "a", encoding="utf-8") as f:
        f.write(f"[{datetime.now()}] âŒ {business_id} ìš”ì²­ ì‹¤íŒ¨\n")
        if error:
            f.write(f"Error: {error}\n")
        f.write(f"Payload: {json.dumps(payload, ensure_ascii=False)}\n\n")

def make_payload(business_id, cursors):
    return {
        "operationName": "getPhotoViewerItems",
        "variables": {
            "input": {
                "businessId": business_id,
                "businessType": "restaurant",
                "cursors": cursors,
                "excludeAuthorIds": [],
                "excludeSection": [],
                "excludeClipIds": [],
                "dateRange": ""
            }
        },
        "query": PHOTO_QUERY
    }

def save_jsonl(filename, photos, output_path):
    filepath = os.path.join(output_path, filename)
    with open(filepath, "w", encoding="utf-8") as f:
        for p in photos:
            f.write(json.dumps(p, ensure_ascii=False) + "\n")

def load_business_ids_range(start=0, end=100):
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    cursor.execute(f"""
        SELECT id, {BUSINESS_ID_COLUMN}
        FROM {TABLE_NAME}
        WHERE {BUSINESS_ID_COLUMN} IS NOT NULL
        LIMIT ? OFFSET ?
    """, (end - start, start))
    rows = cursor.fetchall()
    conn.close()
    ids = []
    for db_id, url in rows:
        match = re.search(r'/restaurant/(\d+)', url)
        if match:
            business_id = match.group(1)
            ids.append((db_id, business_id))
    return ids

def random_delay():
    delay = random.uniform(MIN_DELAY, MAX_DELAY)
    time.sleep(delay)
    return delay

async def extract_cookies_from_browser(page, business_id=None):
    """Playwrightë¥¼ ì‚¬ìš©í•˜ì—¬ ë¸Œë¼ìš°ì €ì—ì„œ ì¿ í‚¤ë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜"""
    try:
        # ìœ íš¨í•œ URL ì„¤ì •
        if business_id:
            url = f"https://m.place.naver.com/restaurant/{business_id}/home"
        else:
            # ë ˆìŠ¤í† ë‘ ëª©ë¡ í˜ì´ì§€
            url = "https://m.place.naver.com/restaurant/list"
        
        # í˜ì´ì§€ ì´ë™
        await page.goto(url, wait_until="networkidle")
        print(f"ğŸ”„ ì„¸ì…˜ ì´ˆê¸°í™” ì¤‘... (URL: {url})")
        
        # í˜ì´ì§€ì™€ ìƒí˜¸ì‘ìš©í•˜ì—¬ ë” ë§ì€ ì¿ í‚¤ ìƒì„±
        # ìŠ¤í¬ë¡¤
        await page.evaluate("""
            () => {
                window.scrollTo(0, 200);
                setTimeout(() => window.scrollTo(0, 400), 300);
                setTimeout(() => window.scrollTo(0, 100), 600);
            }
        """)
        await asyncio.sleep(1)
        
        # Playwrightì—ì„œ ì¿ í‚¤ ê°€ì ¸ì˜¤ê¸°
        cookies = await page.context.cookies()
        
        # ì¿ í‚¤ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
        cookie_dict = {}
        for cookie in cookies:
            if '.naver.com' in cookie.get('domain', ''):
                cookie_dict[cookie['name']] = cookie['value']
        
        print(f"ğŸª Playwrightë¡œ {len(cookie_dict)}ê°œ ì¿ í‚¤ ì¶”ì¶œë¨")
        
        # ì¿ í‚¤ê°€ ë¹„ì–´ìˆìœ¼ë©´ ê¸°ë³¸ê°’ ì„¤ì •
        if not cookie_dict:
            print("âš ï¸ ì¿ í‚¤ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì¿ í‚¤ ì‚¬ìš©...")
            cookie_dict = {
                "NNB": "XLXNYI5U5MBTA",  # ì„ì˜ì˜ ê¸°ë³¸ê°’
                "PLACE_LANGUAGE": "ko"
            }
            
            # ê¸°ë³¸ ì¿ í‚¤ ì„¤ì •
            await page.context.add_cookies([
                {"name": "NNB", "value": "XLXNYI5U5MBTA", "domain": ".naver.com", "path": "/"},
                {"name": "PLACE_LANGUAGE", "value": "ko", "domain": ".place.naver.com", "path": "/"}
            ])
        
        # ë¡œì»¬ ìŠ¤í† ë¦¬ì§€ì—ì„œ ì¤‘ìš” ì •ë³´ í™•ì¸
        local_storage = await page.evaluate("""
            () => {
                try {
                    const storage = {};
                    for (let i = 0; i < localStorage.length; i++) {
                        const key = localStorage.key(i);
                        storage[key] = localStorage.getItem(key);
                    }
                    return storage;
                } catch (e) {
                    console.error('ë¡œì»¬ ìŠ¤í† ë¦¬ì§€ ì ‘ê·¼ ì˜¤ë¥˜:', e);
                    return {};
                }
            }
        """)
        
        if local_storage and isinstance(local_storage, dict):
            print(f"ğŸ“¦ ë¡œì»¬ ìŠ¤í† ë¦¬ì§€ {len(local_storage)}ê°œ í•­ëª© í™•ì¸ë¨")
            # í•„ìš”í•œ ê²½ìš° ë¡œì»¬ ìŠ¤í† ë¦¬ì§€ì—ì„œ ì¤‘ìš” ì •ë³´ ì¿ í‚¤ë¡œ ë³µì‚¬
            for key in ['NNB', 'NID_AUT', 'NID_SES', 'nx_ssl']:
                if key in local_storage and key not in cookie_dict:
                    cookie_dict[key] = local_storage[key]
                    print(f"ğŸ”‘ ë¡œì»¬ ìŠ¤í† ë¦¬ì§€ì—ì„œ '{key}' ì¿ í‚¤ë¡œ ë³µì‚¬")
                    
                    # ì¿ í‚¤ë¡œ ì„¤ì •
                    await page.context.add_cookies([
                        {"name": key, "value": local_storage[key], "domain": ".naver.com", "path": "/"}
                    ])
        
        # í˜„ì¬ user-agent ê°€ì ¸ì˜¤ê¸°
        user_agent = await page.evaluate("navigator.userAgent")
        
        print(f"ğŸª ìµœì¢… íšë“í•œ ì¿ í‚¤ í‚¤: {', '.join(list(cookie_dict.keys())[:5])}...")
        return {
            'cookies': cookie_dict,
            'user_agent': user_agent
        }
    except Exception as e:
        print(f"âŒ ì¿ í‚¤ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ ì¿ í‚¤ ë°˜í™˜
        return {
            'cookies': {
                "NNB": "XLXNYI5U5MBTA",
                "PLACE_LANGUAGE": "ko"
            },
            'user_agent': "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/136.0.0.0 Safari/537.36"
        }

async def refresh_browser_cookies(page, business_id):
    """ë¸Œë¼ìš°ì € ì¿ í‚¤ë¥¼ ìƒˆë¡œê³ ì¹¨"""
    try:
        url = f"https://m.place.naver.com/restaurant/{business_id}/home"
        await page.goto(url, wait_until="networkidle")
        print(f"ğŸ”„ ë¸Œë¼ìš°ì € ì„¸ì…˜ ê°±ì‹  ì¤‘... (URL: {url})")
        
        # ìƒí˜¸ì‘ìš©
        await page.evaluate("""
            () => {
                window.scrollTo(0, 200);
                setTimeout(() => window.scrollTo(0, 400), 300);
                setTimeout(() => window.scrollTo(0, 150), 600);
            }
        """)
        await asyncio.sleep(1)
        
        # ì¿ í‚¤ ê°€ì ¸ì˜¤ê¸°
        cookies = await page.context.cookies()
        
        # ì¿ í‚¤ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
        cookie_dict = {}
        for cookie in cookies:
            if '.naver.com' in cookie.get('domain', ''):
                cookie_dict[cookie['name']] = cookie['value']
        
        print(f"ğŸª ìƒˆë¡œê³ ì¹¨ìœ¼ë¡œ {len(cookie_dict)}ê°œ ì¿ í‚¤ ì¶”ì¶œë¨")
        
        # ì¿ í‚¤ê°€ ë¹„ì–´ìˆìœ¼ë©´ ê¸°ë³¸ê°’ ì„¤ì •
        if not cookie_dict:
            print("âš ï¸ ê°±ì‹  ì¤‘ ì¿ í‚¤ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì¿ í‚¤ ì‚¬ìš©...")
            cookie_dict = {
                "NNB": "XLXNYI5U5MBTA",
                "PLACE_LANGUAGE": "ko"
            }
        
        user_agent = await page.evaluate("navigator.userAgent")
        
        print(f"ğŸª ê°±ì‹ ëœ ì¿ í‚¤ í‚¤: {', '.join(list(cookie_dict.keys())[:5])}...")
        return {
            'cookies': cookie_dict,
            'user_agent': user_agent
        }
    except Exception as e:
        print(f"âŒ ì¿ í‚¤ ê°±ì‹  ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ ì¿ í‚¤ ë°˜í™˜
        return {
            'cookies': {
                "NNB": "XLXNYI5U5MBTA",
                "PLACE_LANGUAGE": "ko"
            },
            'user_agent': "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/136.0.0.0 Safari/537.36"
        }

def make_request_with_cookies(business_id, cursors, browser_data, retry_count=0):
    """ë¸Œë¼ìš°ì €ì—ì„œ íšë“í•œ ì¿ í‚¤ë¥¼ ì‚¬ìš©í•˜ì—¬ requestsë¡œ ìš”ì²­"""
    try:
        payload = make_payload(business_id, cursors)
        
        # í—¤ë” ì„¤ì •
        headers = {
            'Content-Type': 'application/json',
            'User-Agent': browser_data['user_agent'],
            'Referer': f'https://m.place.naver.com/restaurant/{business_id}/photo',
            'Origin': 'https://m.place.naver.com',
            'Accept-Language': 'ko-KR,ko;q=0.9',
            'Cache-Control': 'no-cache',
            'Pragma': 'no-cache',
            'Sec-Ch-Ua': '"Chromium";v="136", "Google Chrome";v="136", "Not.A/Brand";v="99"',
            'Sec-Ch-Ua-Mobile': '?0',
            'Sec-Ch-Ua-Platform': '"macOS"',
            'Sec-Fetch-Dest': 'empty',
            'Sec-Fetch-Mode': 'cors',
            'Sec-Fetch-Site': 'same-site'
        }
        
        # ë””ë²„ê¹…: ìš”ì²­ ì „ í—¤ë”ì™€ ì¿ í‚¤ ì¶œë ¥
        print("\nğŸ” ë””ë²„ê¹… ì •ë³´ - API ìš”ì²­")
        print(f"ğŸ“‹ ìš”ì²­ URL: https://api.place.naver.com/graphql")
        print(f"ğŸ“‹ ë¹„ì¦ˆë‹ˆìŠ¤ ID: {business_id}")
        # print(f"ğŸ“‹ í—¤ë” ì •ë³´:")
        # for k, v in headers.items():
        #     print(f"   - {k}: {v}")
        # print(f"ğŸ“‹ ì¿ í‚¤ ì •ë³´ ({len(browser_data['cookies'])}ê°œ):")
        # for k, v in browser_data['cookies'].items():
        #     # ê°’ì´ ë„ˆë¬´ ê¸¸ë©´ ì¼ë¶€ë§Œ í‘œì‹œ
        #     display_value = v[:30] + "..." if len(v) > 30 else v
        #     print(f"   - {k}: {display_value}")
        
        # ìš”ì²­ ë³´ë‚´ê¸°
        response = requests.post(
            "https://api.place.naver.com/graphql",
            json=payload,
            headers=headers,
            cookies=browser_data['cookies'],
            timeout=10
        )
        
        # ì‘ë‹µ í™•ì¸
        if response.status_code != 200:
            print(f"âš ï¸ API ì‘ë‹µ ì˜¤ë¥˜: {response.status_code}")
            print(f"ğŸ“‹ ì‘ë‹µ ë‚´ìš©: {response.text[:200]}...")
            if retry_count < MAX_RETRIES:
                retry_delay = random.uniform(1, 3) * (retry_count + 1)
                print(f"ğŸ”„ {retry_delay:.1f}ì´ˆ í›„ ì¬ì‹œë„ ({retry_count + 1}/{MAX_RETRIES})...")
                time.sleep(retry_delay)
                return make_request_with_cookies(business_id, cursors, browser_data, retry_count + 1)
            return None
        
        data = response.json()
        
        # ë””ë²„ê¹…: ì‘ë‹µ ë°ì´í„° ì¼ë¶€ ì¶œë ¥
        print(f"ğŸ“‹ ì‘ë‹µ ìƒíƒœ ì½”ë“œ: {response.status_code}")
        if data and 'data' in data and 'photoViewer' in data['data']:
            photo_count = len(data['data']['photoViewer'].get('photos', []))
            print(f"ğŸ“‹ ì‘ë‹µì—ì„œ ì‚¬ì§„ ê°œìˆ˜: {photo_count}ì¥")
        
        return data
        
    except Exception as e:
        print(f"âŒ ìš”ì²­ ì˜ˆì™¸: {e}")
        if retry_count < MAX_RETRIES:
            retry_delay = random.uniform(1, 3) * (retry_count + 1)
            print(f"ğŸ”„ {retry_delay:.1f}ì´ˆ í›„ ì¬ì‹œë„ ({retry_count + 1}/{MAX_RETRIES})...")
            time.sleep(retry_delay)
            return make_request_with_cookies(business_id, cursors, browser_data, retry_count + 1)
        return None

async def main():
    start = int(os.environ.get("START_INDEX", 0))
    end = int(os.environ.get("END_INDEX", 100))
    print(f"ğŸ“¦ í˜„ì¬ ì»¨í…Œì´ë„ˆëŠ” {start} ~ {end} ë²”ìœ„ë¥¼ ë‹´ë‹¹í•©ë‹ˆë‹¤.")

    BASE_DIR = os.path.dirname(os.path.abspath(__file__))
    output_path = os.path.join(BASE_DIR, "crawl_photo")
    os.makedirs(output_path, exist_ok=True)

    business_ids = load_business_ids_range(start, end)
    if not business_ids:
        print("âš ï¸ ê°€ì ¸ì˜¬ ì—…ì²´ IDê°€ ì—†ìŠµë‹ˆë‹¤. ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return

    # Playwright ì´ˆê¸°í™”
    print("ğŸŒ Playwright ì´ˆê¸°í™” ì¤‘...")
    async with async_playwright() as p:
        # ë¸Œë¼ìš°ì € ì‹œì‘ - í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œ í•´ì œ (ë¸Œë¼ìš°ì € í™”ë©´ í‘œì‹œ)
        browser = await p.chromium.launch(headless=False)
        context = await browser.new_context(
            viewport={"width": 1280, "height": 800},
            user_agent="Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/136.0.0.0 Safari/537.36"
        )
        
        # ë¸Œë¼ìš°ì € ì°½ ê²€ì‚¬ë¥¼ ìœ„í•œ ëŒ€ê¸°ì‹œê°„
        print("âš ï¸ ë¸Œë¼ìš°ì €ê°€ í‘œì‹œë©ë‹ˆë‹¤. ìˆ˜ë™ìœ¼ë¡œ ë¡œê·¸ì¸í•˜ë ¤ë©´ ì§€ê¸ˆ ë¡œê·¸ì¸í•˜ì„¸ìš”.")
        print("â±ï¸ 10ì´ˆ í›„ì— ìë™ í¬ë¡¤ë§ì´ ì‹œì‘ë©ë‹ˆë‹¤...")
        await asyncio.sleep(10)  # ì‚¬ìš©ìê°€ ë¸Œë¼ìš°ì €ë¥¼ í™•ì¸í•˜ê³  í•„ìš”ì‹œ ìˆ˜ë™ ë¡œê·¸ì¸í•  ì‹œê°„
        
        # ì²« í˜ì´ì§€ ìƒì„±
        page = await context.new_page()
        
        # ì²« ë²ˆì§¸ ì—…ì²´ ì •ë³´ë¡œ ì´ˆê¸° ì¿ í‚¤ íšë“
        first_db_id, first_business_id = business_ids[0]
        print(f"ğŸ”‘ ì²« ë²ˆì§¸ ì—…ì²´({first_business_id})ë¡œ ì´ˆê¸° ì¿ í‚¤ íšë“ ì¤‘...")
        browser_data = await extract_cookies_from_browser(page, first_business_id)
        
        # ë””ë²„ê¹…: íšë“í•œ ëª¨ë“  ì¿ í‚¤ ìƒì„¸ ì¶œë ¥
        print("\nğŸ” ë””ë²„ê¹… ì •ë³´ - íšë“í•œ ì¿ í‚¤")
        print(f"ğŸ“‹ ì¿ í‚¤ ê°œìˆ˜: {len(browser_data['cookies'])}")
        print(f"ğŸ“‹ ìƒì„¸ ì¿ í‚¤ ëª©ë¡:")
        for k, v in browser_data['cookies'].items():
            # ê°’ì´ ë„ˆë¬´ ê¸¸ë©´ ì¼ë¶€ë§Œ í‘œì‹œ
            display_value = v[:30] + "..." if len(v) > 30 else v
            print(f"   - {k}: {display_value}")
        print(f"ğŸ“‹ User-Agent: {browser_data['user_agent']}")
        
        print(f"ğŸ“ ì¿ í‚¤ íšë“ ì™„ë£Œ: {len(browser_data['cookies'])} ê°œì˜ ì¿ í‚¤")

        # ê³„ì† ì§„í–‰í• ì§€ í™•ì¸
        print("\nâš ï¸ íšë“í•œ ì¿ í‚¤ë¡œ í¬ë¡¤ë§ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
        print("â±ï¸ 5ì´ˆ í›„ì— ìë™ í¬ë¡¤ë§ì´ ì‹œì‘ë©ë‹ˆë‹¤...")
        await asyncio.sleep(5)  # ì‚¬ìš©ìê°€ ì¿ í‚¤ ì •ë³´ë¥¼ í™•ì¸í•  ì‹œê°„
        
        success_count = 0
        skip_count = 0
        error_count = 0
        cookie_refresh_count = 0

        for i, (db_id, business_id) in enumerate(tqdm(business_ids, desc="ğŸ“¦ ë²”ìœ„ ë‚´ ì—…ì²´ ì²˜ë¦¬")):
            try:
                print(f"\nğŸš€ í¬ë¡¤ë§ ì‹œì‘: {business_id} (DB ID={db_id})")
                
                # ì£¼ê¸°ì ìœ¼ë¡œ ì¿ í‚¤ ë¦¬í”„ë ˆì‹œ (10ê°œ ì—…ì²´ë§ˆë‹¤)
                if i > 0 and i % 10 == 0:
                    print("ğŸ”„ ë¸Œë¼ìš°ì € ì¿ í‚¤ ë¦¬í”„ë ˆì‹œ ì¤‘...")
                    browser_data = await refresh_browser_cookies(page, business_id)
                    cookie_refresh_count += 1
                    
                    # ë””ë²„ê¹…: ë¦¬í”„ë ˆì‹œëœ ëª¨ë“  ì¿ í‚¤ ìƒì„¸ ì¶œë ¥
                    print("\nğŸ” ë””ë²„ê¹… ì •ë³´ - ë¦¬í”„ë ˆì‹œëœ ì¿ í‚¤")
                    print(f"ğŸ“‹ ì¿ í‚¤ ê°œìˆ˜: {len(browser_data['cookies'])}")
                    print(f"ğŸ“‹ ìƒì„¸ ì¿ í‚¤ ëª©ë¡:")
                    for k, v in browser_data['cookies'].items():
                        # ê°’ì´ ë„ˆë¬´ ê¸¸ë©´ ì¼ë¶€ë§Œ í‘œì‹œ
                        display_value = v[:30] + "..." if len(v) > 30 else v
                        print(f"   - {k}: {display_value}")
                    
                    print(f"ğŸ“ ì¿ í‚¤ ë¦¬í”„ë ˆì‹œ ì™„ë£Œ (#{cookie_refresh_count})")
                
                all_photos = []
                cursors = [
                    {"id": "biz"},
                    {"id": "cp0"},
                    {"id": "visitorReview"},
                    {"id": "clip"},
                    {"id": "imgSas"}
                ]

                for page_num in range(MAX_PAGES):
                    print(f"ğŸ“„ í˜ì´ì§€ {page_num + 1} ìš”ì²­ ì¤‘...")
                    
                    # requestsë¡œ ìš”ì²­ (ë¸Œë¼ìš°ì € ì¿ í‚¤ ì‚¬ìš©)
                    data = make_request_with_cookies(business_id, cursors, browser_data)
                    
                    if not data:
                        print(f"âš ï¸ fetch() ì‹¤íŒ¨ or ì‘ë‹µ ì—†ìŒ â†’ ë¸Œë¼ìš°ì € ì¿ í‚¤ ê°±ì‹  í›„ ì¬ì‹œë„")
                        browser_data = await refresh_browser_cookies(page, business_id)
                        cookie_refresh_count += 1
                        
                        # ì¿ í‚¤ ê°±ì‹  í›„ ì¬ì‹œë„
                        data = make_request_with_cookies(business_id, cursors, browser_data)
                        if not data:
                            print(f"âš ï¸ ì¬ì‹œë„ ì‹¤íŒ¨, ê±´ë„ˆëœ€")
                            skip_count += 1
                            break

                    viewer = data.get('data', {}).get('photoViewer', {})
                    photos = viewer.get('photos') or []
                    cursors_data = viewer.get('cursors', [])

                    if not photos:
                        print(f"âš ï¸ ì‚¬ì§„ ì—†ìŒ, ì¢…ë£Œ")
                        break

                    for photo in photos:
                        author = photo.get("author") or {}
                        all_photos.append({
                            "url": photo.get("originalUrl"),
                            "desc": photo.get("desc"),
                            "author": author.get("nickname"),
                            "video": photo.get("video"),
                            "width": photo.get("width"),
                            "height": photo.get("height"),
                            "date": photo.get("date"),
                            "viewId": photo.get("viewId")
                        })

                    next_cursor = None
                    for cursor in cursors_data:
                        if cursor["id"] == "biz" and cursor.get("hasNext") and cursor.get("lastCursor"):
                            next_cursor = cursor["lastCursor"]
                    if not next_cursor:
                        print(f"âœ… ë‹¤ìŒ ì»¤ì„œ ì—†ìŒ, ì¢…ë£Œ")
                        break
                    cursors[0] = {"id": "biz", "lastCursor": next_cursor}
                    
                    # í˜ì´ì§€ ê°„ ë”œë ˆì´ ëœë¤í™”
                    delay = random_delay()
                    print(f"â±ï¸ ë‹¤ìŒ í˜ì´ì§€ ìš”ì²­ê¹Œì§€ {delay:.1f}ì´ˆ ëŒ€ê¸° ì¤‘...")

                if all_photos:
                    filename = f"{db_id}_photo_{business_id}.jsonl"
                    save_jsonl(filename, all_photos, output_path)
                    print(f"âœ… ì €ì¥ ì™„ë£Œ: {filename} ({len(all_photos)}ì¥)")
                    success_count += 1
                else:
                    print(f"âš ï¸ ìˆ˜ì§‘ëœ ì‚¬ì§„ ì—†ìŒ")
                    skip_count += 1
                    
                # ì—…ì²´ ê°„ ë”œë ˆì´ ëœë¤í™”
                if db_id != business_ids[-1][0]:  # ë§ˆì§€ë§‰ ì—…ì²´ê°€ ì•„ë‹ˆë©´
                    delay = random.uniform(0, 1)
                    print(f"â±ï¸ ë‹¤ìŒ ì—…ì²´ í¬ë¡¤ë§ê¹Œì§€ {delay:.1f}ì´ˆ ëŒ€ê¸° ì¤‘...")
                    time.sleep(delay)

            except Exception as e:
                print(f"âŒ ì˜ˆì™¸ ë°œìƒ: {e}")
                log_failure(business_id, {}, error=str(e))
                error_count += 1
                # ì—ëŸ¬ í›„ ë³µêµ¬ ì‹œê°„
                time.sleep(random.uniform(5, 10))
                continue

        print("\nğŸ“Š í¬ë¡¤ë§ ìš”ì•½")
        print(f"âœ… ì„±ê³µ: {success_count}")
        print(f"âš ï¸ ìŠ¤í‚µ: {skip_count}")
        print(f"âŒ ì‹¤íŒ¨: {error_count}")
        print(f"ğŸ”„ ì¿ í‚¤ ë¦¬í”„ë ˆì‹œ: {cookie_refresh_count}íšŒ")
        
        # ë¸Œë¼ìš°ì € ì¢…ë£Œ
        await browser.close()

if __name__ == "__main__":
    asyncio.run(main())
